# Evaluation Report: Distributed System API Gateway

**Date:** {date}
**Run Label:** {run_label}

## 1. Experimental Setup
- **Hardware environment:** {hardware_env}
- **Operating system & versions:** {software_env}
- **Number of containerized nodes:** {num_nodes}
- **System under test:** HTTP API gateway at `{target_url}`
- **Workload specifications:**
  - Warmup requests: {warmup}
  - Requests per level: {requests_per_level}
  - Concurrency levels: {concurrency_levels}
  - Timeout per request: {timeout_seconds}s
  - Payload: `{payload}`

> Notes: Replace placeholders above with your exact machine types, CPU/GPU counts, memory, network, container image versions, and orchestration details. If you scale the number of service replicas between runs, list each run label and replica counts.

## 2. Performance & Scalability Results

### 2.1 Throughput vs Concurrency
![Throughput](./{run_label}_throughput.png)

### 2.2 p95 Latency vs Concurrency
![p95 Latency](./{run_label}_p95_latency.png)

### 2.3 Error Rate vs Concurrency
![Error Rate](./{run_label}_error_rate.png)

### 2.4 Summary Table
See `{run_label}_summary_clean.csv` for the exact numbers (throughput, latency percentiles, error rates).

## 3. Analysis of System-Design Trade-offs

- **Backpressure & Queueing:** Discuss how the gateway or downstream services handle bursts as concurrency increases. Note at which concurrency the p95 latency accelerates and error rate starts to rise.
- **Scalability:** Compare runs at different replica counts (e.g., 1×, 2×, 4× service instances). Verify whether throughput scales close to linearly and whether latency remains acceptable.
- **Fault tolerance:** Summarize error patterns (HTTP status codes, timeouts). Identify whether failures cluster under high concurrency or specific payloads.
- **Bottlenecks:** Hypothesize where hotspots occur (gateway CPU, app threads, DB, model server, network I/O). Support with evidence if you can collect node-level metrics.
- **Cost-performance:** If you have per-node specs/costs, estimate cost per 1000 successful requests at target SLOs (e.g., p95 < 200 ms, error rate < 1%).

## 4. Conclusions & Recommendations

- **Target operating point:** Choose a concurrency where throughput is high and p95 latency/error rate meet SLOs.
- **Capacity planning:** Given observed scaling, estimate how many replicas are required for your production RPS targets.
- **Next steps:** E.g., enable connection pooling, increase worker processes, add caching, tune timeouts/retries, or shard queues.

---

*This report was generated by the included scripts (`benchmark.py`, `analyze.py`, `generate_report.py`).*
